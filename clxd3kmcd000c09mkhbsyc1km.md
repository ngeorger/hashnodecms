---
title: "Ex-empleado de OpenAI habla sobre la AGI, la superinteligencia y la dinámica de poder global"
datePublished: Thu Jun 13 2024 10:08:44 GMT+0000 (Coordinated Universal Time)
cuid: clxd3kmcd000c09mkhbsyc1km
slug: ex-empleado-de-openai-habla-sobre-la-agi-la-superinteligencia-y-la-dinamica-de-poder-global-1
canonical: https://sredevops.org/es/ex-empleado-de-openai-habla-sobre-la-agi-la-superinteligencia-y-la-dinamica-de-poder-global/
cover: https://cdn.hashnode.com/res/hashnode/imageupload/v1718273323415/dff46921-eeb9-4483-b67e-8fcedda7d2a0.webp
tags: data-science, opensource, videos, opinion, espanol, mlops, inteligencia-artificial, gobierno

---

![Ex-empleado de OpenAI habla sobre la AGI, la superinteligencia y la dinámica de poder global](https://cdn.hashnode.com/res/hashnode/imageupload/v1718273322205/6a5aaad9-68aa-4580-8523-16bc78ff7be3.webp)

En un episodio reciente del podcast Dwarkesh Patel, el ex-empleado de OpenAI, [Leopold Ashenbrenner](https://www.linkedin.com/in/leopold-aschenbrenner/?ref=sredevops.org), miembro del ahora disuelto equipo de _superalineación_, brindó una visión cautivadora y perspicaz del mundo de la `AI` avanzada, su trayectoria potencial y sus implicaciones para la humanidad.

<iframe width="200" height="113" src="https://www.youtube.com/embed/yLbpNJEqSw4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Ex-OpenAI Employee Just Revealed it ALL!"></iframe>

### Analizando las ideas de Ashenbrenner:

Ashenbrenner, conocido por su profundo conocimiento de la `AI`, articuló con elocuencia sus puntos de vista sobre una variedad de temas, que incluyen:

*   **El estado actual de la AGI:** Habló sobre las capacidades de `GPT-4` y si representa la "chispa" de la Inteligencia Artificial General, como sugieren algunos expertos. También exploró la línea de tiempo potencial desde la `AGI` hasta la superinteligencia, cuestionando si sería una evolución gradual o una explosión rápida.
*   **Más allá de los apocalípticos y utópicos de la `AI`:** Ashenbrenner desafía la dicotomía simplista de los apocalípticos de la `AI` (que abogan por un alto total en el desarrollo de la `AI`) y los utópicos (que visualizan un futuro idílico impulsado por la `AI`). Él enfatiza la necesidad de considerar un espectro más amplio de posibilidades y consecuencias potenciales.
*   **La geopolítica de la superinteligencia:** Una preocupación clave planteada fue el potencial de la `AI` para perturbar el equilibrio de poder global. Ashenbrenner argumenta que naciones como China ven la supremacía de la `AI` como crucial para sus intereses nacionales. Advierte sobre una posible carrera armamentista de `AI`, con consecuencias devastadoras si una nación obtiene una ventaja decisiva.
*   **La importancia de "desatar" la `AI`:** Usó el término "desatar" para describir el proceso de desbloquear todo el potencial de los sistemas de `AI`. Esto implica ir más allá del simple pre-entrenamiento en conjuntos de datos masivos y desarrollar técnicas para que la `AI` aprenda y se adapte de forma autónoma, similar a `AlphaGo` y `AlphaStar` de DeepMind.
*   **La `AI` como catalizador del rápido avance tecnológico:** Ashenbrenner sugiere que la `AI` podría acelerar significativamente el progreso tecnológico, comprimiendo potencialmente décadas de innovación en unos pocos años. Esto podría conducir a una "explosión de inteligencia", con profundas implicaciones para varios campos, incluyendo la robótica y las aplicaciones militares.
*   **El potencial de las dictaduras impulsadas por la `AI`:** Una de las posibilidades más escalofriantes discutidas fue el potencial de la `AI` para empoderar a los regímenes autoritarios. Ashenbrenner pinta una imagen de vigilancia, censura y represión habilitadas por la `AI`, lo que sugiere que la superinteligencia podría consolidar el control de las dictaduras en las próximas generaciones.

### Conclusiones y reflexiones clave:

La entrevista de Ashenbrenner sirve como un duro recordatorio de que el desarrollo de la `AI` avanzada no es simplemente un esfuerzo tecnológico sino también profundamente político y social. Algunas conclusiones clave incluyen:

*   **La necesidad de matices y una consideración amplia:** Es crucial ir más allá de las narrativas simplistas de fatalidad o utopía de la `AI`. Debemos participar en discusiones matizadas sobre los beneficios y riesgos potenciales de la `AI`, explorando una gama más amplia de futuros posibles.
*   **La urgencia de la cooperación internacional:** Para mitigar los riesgos de una carrera armamentista de `AI` y garantizar que el desarrollo de la `AI` beneficie a toda la humanidad, la cooperación internacional es primordial. Esto incluye establecer pautas éticas, fomentar la transparencia y promover la investigación y el despliegue responsable de la `AI`.
*   **La importancia de la preparación social:** A medida que la `AI` transforma rápidamente nuestro mundo, es esencial prepararse para su impacto social. Esto incluye abordar el posible desplazamiento laboral, garantizar un acceso equitativo a los beneficios de la `AI` y protegerse contra la discriminación y el sesgo impulsados por la `AI`.

Las ideas de Ashenbrenner ofrecen una perspectiva aleccionadora pero que invita a la reflexión sobre el futuro de la `AI` y su impacto potencial en la humanidad. Es un llamado a la acción para que investigadores, legisladores y ciudadanos por igual participen en un diálogo informado y proactivo para dar forma a la trayectoria del desarrollo de la `AI` y garantizar un futuro donde esta poderosa tecnología sirva como una fuerza para el bien.

### Paper completo:

[

SITUATIONAL AWARENESS: The Decade Ahead

Leopold Aschenbrenner, June 2024. Fuente: https://situational-awareness.ai/

situationalawareness.pdf

20 MB

.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}download-circle

](https://sredevops.org/content/files/2024/06/situationalawareness.pdf "Download")

### Entrevista completa original:

<iframe width="200" height="113" src="https://www.youtube.com/embed/zdbVtZIn9IM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Leopold Aschenbrenner - 2027 AGI, China/US Super-Intelligence Race, &amp; The Return of History"></iframe>